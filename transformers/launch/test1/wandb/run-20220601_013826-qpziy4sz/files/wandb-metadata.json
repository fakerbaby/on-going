{
    "os": "Linux-4.15.0-169-generic-x86_64-with-debian-buster-sid",
    "python": "3.7.13",
    "heartbeatAt": "2022-05-31T17:38:41.514929",
    "startedAt": "2022-05-31T17:38:26.281304",
    "docker": null,
    "gpu": "NVIDIA GeForce RTX 3090",
    "gpu_count": 8,
    "cpu_count": 48,
    "cuda": null,
    "args": [
        "--output_dir",
        "../../checkpoints/glue/rte/20220601/roberta_base.ne80.warm0.06.wd0.1.seed42.",
        "--model_name_or_path",
        "roberta-base",
        "--task_name",
        "rte",
        "--do_train",
        "--do_eval",
        "--max_seq_length",
        "512",
        "--per_device_train_batch_size",
        "32",
        "--per_device_eval_batch_size",
        "32",
        "--learning_rate",
        "5e-4",
        "--lr_scheduler_type",
        "linear",
        "--num_train_epochs",
        "80",
        "--logging_steps",
        "100",
        "--evaluation_strategy",
        "epoch",
        "--save_strategy",
        "epoch",
        "--save_steps",
        "5000",
        "--eval_steps",
        "5000",
        "--warmup_ratio",
        "0.06",
        "--gradient_accumulation_steps",
        "1",
        "--apply_lora",
        "--lora_r",
        "8",
        "--lora_alpha",
        "16",
        "--seed",
        "42",
        "--weight_decay",
        "0.1",
        "--report_to",
        "wandb",
        "--run_name",
        "roberta_base.ne80.warm0.06.wd0.1.seed42.",
        "--disable_tqdm",
        "True",
        "--greater_is_better",
        "True",
        "--overwrite_output_dir",
        "--load_best_model_at_end",
        "yes",
        "--fp16"
    ],
    "state": "running",
    "program": "../../examples/run_glue.py",
    "codePath": "examples/run_glue.py",
    "git": {
        "remote": "https://github.com/huggingface/transformers",
        "commit": "b24201fa44e1a14e83be890dcbc231e926c37ec1"
    },
    "email": "794598816@qq.com",
    "root": "/root/workspace/on-going/transformers",
    "host": "18dd82b3604a",
    "username": "root",
    "executable": "/opt/conda/envs/LoRA/bin/python"
}
